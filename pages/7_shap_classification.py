import streamlit as st
import pandas as pd
import numpy as np
import shap
import matplotlib.pyplot as plt
import plotly.express as px
from lightgbm import LGBMClassifier
from io import StringIO
from sklearn.model_selection import KFold
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score
)
from app import memo_sidebar
import pandas.api.types as ptypes

# ============================================
# ğŸ“ ãƒ¡ãƒ¢ Sidebar
# ============================================
memo_sidebar()

# ============================================
# ğŸ”§ çŠ¶æ…‹ç®¡ç†
# ============================================
for key in ["model_trained", "shap_run", "cv_mode"]:
    if key not in st.session_state:
        st.session_state[key] = False

# ============================================
# ã‚¿ã‚¤ãƒˆãƒ«
# ============================================
st.title("ğŸ”¥ LightGBM åˆ†é¡ + SHAPï¼ˆå˜ä¸€ & CVï¼‰+ Interaction SHAP")


# ============================================
# ğŸ”§ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# ============================================
@st.cache_data
def load_data(file_bytes, name, sheet=None):
    if name.endswith(".csv"):
        return pd.read_csv(StringIO(file_bytes.decode("utf-8", errors="ignore")))
    if name.endswith(".xlsx"):
        if sheet:
            return pd.read_excel(file_bytes, sheet_name=sheet)
        xls = pd.ExcelFile(file_bytes)
        return pd.read_excel(file_bytes, sheet_name=xls.sheet_names[0])
    return pd.read_csv(StringIO(file_bytes.decode("utf-8", errors="ignore")))

# ç‰¹å¾´é‡ã®ã‚«ãƒ†ã‚´ãƒªè‡ªå‹•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
def encode_categoricals(df: pd.DataFrame) -> pd.DataFrame:
    df2 = df.copy()
    for col in df2.columns:
        if df2[col].dtype == "object" or ptypes.is_categorical_dtype(df2[col]):
            df2[col] = df2[col].astype("category").cat.codes
    return df2


# ============================================
# ğŸ”¼ ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
# ============================================
uploaded = st.file_uploader(
    "åˆ†é¡å•é¡Œç”¨ CSV / Excel ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["csv", "xlsx"],
    key="lgbm_clf_uploader",
)

if uploaded is None:
    st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

file_bytes = uploaded.getvalue()
file_name = uploaded.name.lower()

sheet_name = None
if file_name.endswith(".xlsx"):
    xls = pd.ExcelFile(uploaded)
    sheet_name = st.selectbox("ğŸ“„ ã‚·ãƒ¼ãƒˆé¸æŠ", xls.sheet_names)

df = load_data(file_bytes, file_name, sheet_name)

st.subheader("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ Preview")
st.dataframe(df.head())


# ============================================
# ğŸ¯ ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¸æŠï¼ˆåˆ†é¡å•é¡Œï¼‰
# ============================================
target_col = st.selectbox("ğŸ¯ ç›®çš„å¤‰æ•°ï¼ˆã‚¯ãƒ©ã‚¹ï¼‰", df.columns)

X_orig = df.drop(columns=[target_col])
y_raw = df[target_col]

# ID ã£ã½ã„åˆ—ã¯è‡ªå‹•é™¤å¤–
id_cols = [c for c in X_orig.columns if c.lower() == "id" or c.lower().endswith("id")]
if id_cols:
    X_orig = X_orig.drop(columns=id_cols)
    st.warning(f"ID ç³»åˆ— {id_cols} ã‚’ç‰¹å¾´é‡ã‹ã‚‰é™¤å¤–ã—ã¾ã—ãŸã€‚")

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’ã‚«ãƒ†ã‚´ãƒª or æ•´æ•°åŒ–
y = pd.Categorical(y_raw).codes


# ç‰¹å¾´é‡ã‚’ LightGBM ç”¨ã«æ•°å€¤åŒ–
X_num = encode_categoricals(X_orig)

# NaN ã¯äº‹å‰å‰Šé™¤
combined = pd.concat([X_num, pd.Series(y, name=target_col)], axis=1)
n_before = len(combined)
combined = combined.dropna()
n_after = len(combined)

if n_after < n_before:
    st.warning(f"NaN ã‚’å«ã‚€ {n_before - n_after} è¡Œã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")

X_num = combined[X_num.columns]
y = combined[target_col]
X_disp = X_orig.loc[X_num.index]  # è¡¨ç¤ºç”¨ï¼ˆã‚«ãƒ†ã‚´ãƒªå€¤ï¼‰


st.write("ğŸ“Œ X shape:", X_num.shape)
st.write("ğŸ“Œ y shape:", y.shape)


# ============================================
# ğŸ”§ LightGBM åˆ†é¡ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# ============================================
def train_lgbm_classifier(X_train, y_train):
    model = LGBMClassifier(
        n_estimators=300,
        random_state=42,
        boosting_type="gbdt",
        class_weight="balanced"
    )
    model.fit(X_train, y_train)
    return model


# ============================================
# ğŸ“Š 5-fold CV æ€§èƒ½
# ============================================
@st.cache_data
def compute_cv_metrics(X, y, n_splits=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)

    acc_list = []
    pre_list = []
    rec_list = []
    f1_list = []
    auc_list = []

    for tr_idx, val_idx in kf.split(X):
        X_train, X_val = X.iloc[tr_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[tr_idx], y.iloc[val_idx]

        model = LGBMClassifier(
            n_estimators=300,
            random_state=42,
            boosting_type="gbdt",
            class_weight="balanced"
        )
        model.fit(X_train, y_train)

        pred = model.predict(X_val)
        prob = model.predict_proba(X_val)[:, 1]

        acc_list.append(accuracy_score(y_val, pred))
        pre_list.append(precision_score(y_val, pred, zero_division=0))
        rec_list.append(recall_score(y_val, pred))
        f1_list.append(f1_score(y_val, pred))
        auc_list.append(roc_auc_score(y_val, prob))

    metrics_df = pd.DataFrame({
        "Metric": ["Accuracy", "Precision", "Recall", "F1", "ROC-AUC"],
        "Fold1": [acc_list[0], pre_list[0], rec_list[0], f1_list[0], auc_list[0]],
        "Fold2": [acc_list[1], pre_list[1], rec_list[1], f1_list[1], auc_list[1]],
        "Fold3": [acc_list[2], pre_list[2], rec_list[2], f1_list[2], auc_list[2]],
        "Fold4": [acc_list[3], pre_list[3], rec_list[3], f1_list[3], auc_list[3]],
        "Fold5": [acc_list[4], pre_list[4], rec_list[4], f1_list[4], auc_list[4]],
        "Mean":  [np.mean(acc_list), np.mean(pre_list), np.mean(rec_list), np.mean(f1_list), np.mean(auc_list)],
        "Std":   [np.std(acc_list),  np.std(pre_list),  np.std(rec_list),  np.std(f1_list),  np.std(auc_list)],
    })

    return metrics_df


# ============================================
# ğŸš€ LightGBM ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
# ============================================
if st.button("ğŸš€ LightGBM ãƒ¢ãƒ‡ãƒ«å­¦ç¿’"):
    st.session_state["model"] = train_lgbm_classifier(X_num, y)
    st.session_state["model_trained"] = True
    st.success("LightGBM ã®å­¦ç¿’ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    metrics_df = compute_cv_metrics(X_num, y, n_splits=5)

    st.subheader("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ï¼ˆ5-fold CVï¼‰")
    st.dataframe(metrics_df)


# ============================================
# ğŸ” SHAPï¼ˆåˆ†é¡ï¼‰
# ============================================
@st.cache_data
def compute_shap_and_interactions(X, _model):
    explainer = shap.TreeExplainer(_model)

    # LightGBM åˆ†é¡ã¯ shap_values ãŒã‚¯ãƒ©ã‚¹ã”ã¨ã«è¿”ã‚‹ï¼ˆlist ã®å½¢ï¼‰
    shap_values = explainer.shap_values(X)  # List[F] or ndarray
    expected_value = explainer.expected_value

    # Interaction SHAPï¼ˆã‚¯ãƒ©ã‚¹0ã®ã¿ã‚’æ¡ç”¨ï¼‰
    interaction_values = explainer.shap_interaction_values(X)
    if isinstance(interaction_values, list):
        interaction_values = interaction_values[0]  # ã‚¯ãƒ©ã‚¹0ã‚’ä½¿ç”¨

    return expected_value, shap_values, interaction_values


# ============================================
# SHAP ãƒœã‚¿ãƒ³
# ============================================
if st.button("ğŸ“Š SHAP è¨ˆç®—ï¼ˆå˜ä¸€ãƒ¢ãƒ‡ãƒ«ï¼‰"):
    if not st.session_state["model_trained"]:
        st.warning("å…ˆã« LightGBM ã‚’å­¦ç¿’ã—ã¦ãã ã•ã„ã€‚")
    else:
        st.session_state["shap_run"] = True


# ============================================
# SHAP è¡¨ç¤º
# ============================================
if st.session_state["shap_run"]:

    model = st.session_state["model"]

    expected_value, shap_values, interaction_values = compute_shap_and_interactions(
        X_num, model
    )

    st.header("ğŸ“Š SHAP è§£æï¼ˆåˆ†é¡ï¼‰")

    # SHAP Summaryï¼ˆã‚¯ãƒ©ã‚¹0ã® shap_values ã‚’æ¡ç”¨ï¼‰
    st.subheader("ğŸ“Œ SHAP Summary Plotï¼ˆClass 0ï¼‰")
    fig, ax = plt.subplots(figsize=(10, 5))
    # --- shap_values ã®æ­£ã—ã„å–ã‚Šå‡ºã— ---
    if isinstance(shap_values, list):
        # Binary classification â†’ ã‚¯ãƒ©ã‚¹1ï¼ˆpositiveï¼‰ã® SHAP ã‚’ä½¿ã†
        shap_matrix = shap_values[1]
    else:
        shap_matrix = shap_values

    # --- Summary Plot ---
    shap.summary_plot(shap_matrix, X_disp, show=False)
    st.pyplot(fig)
    plt.close(fig)

    # LightGBM Importance
    st.subheader("ğŸ”¥ LightGBM Feature Importance")
    imp_df = (
        pd.DataFrame({"Feature": X_num.columns, "Importance": model.feature_importances_})
        .sort_values(by="Importance", ascending=False)
    )
    fig_imp = px.bar(
        imp_df,
        x="Importance",
        y="Feature",
        orientation="h",
        title="LightGBM Feature Importance",
    )
    fig_imp.update_layout(yaxis=dict(categoryorder="total ascending"))
    st.plotly_chart(fig_imp, width="stretch")

    # Mean|SHAP|
    st.subheader("ğŸ“ˆ Mean |SHAP| Feature Importanceï¼ˆClass 0ï¼‰")
    shap_mean = np.abs(shap_matrix).mean(axis=0)
    shap_imp_df = pd.DataFrame({
        "Feature": X_num.columns,
        "Mean|SHAP|": shap_mean
    }).sort_values("Mean|SHAP|", ascending=False)

    fig_shap = px.bar(
        shap_imp_df,
        x="Mean|SHAP|",
        y="Feature",
        orientation="h",
        title="SHAP Feature Importanceï¼ˆå¹³å‡çµ¶å¯¾å€¤ï¼‰",
    )
    fig_shap.update_layout(yaxis=dict(categoryorder="total ascending"))
    st.plotly_chart(fig_shap, width="stretch")

    # ============================================
    # Dependence Plotï¼ˆåˆ†é¡ï¼‰
    # ============================================
    st.subheader("ğŸ“‰ SHAP Dependence Plotï¼ˆClass 0ï¼‰")
    dep_feat = st.selectbox("ç‰¹å¾´é‡ï¼ˆXè»¸ï¼‰", X_num.columns)

    if dep_feat:
        fig_dep, ax_dep = plt.subplots(figsize=(7, 5))
        shap.dependence_plot(
            ind=dep_feat,
            shap_values=shap_matrix,
            features=X_disp,
            ax=ax_dep,
            show=False
        )
        st.pyplot(fig_dep)
        plt.close(fig_dep)

    # ============================================
    # Waterfallï¼ˆåˆ†é¡ï¼‰
    # ============================================
    st.subheader("ğŸ“œ SHAP Waterfall Plotï¼ˆå€‹åˆ¥, Class 0ï¼‰")
    idx = st.number_input("è¡Œç•ªå·", 0, len(X_num)-1, 0)

    shap_ex = shap.Explanation(
        values=shap_matrix[idx],
        base_values=expected_value[1] if isinstance(expected_value, list) else expected_value,
        data=X_disp.iloc[idx],
        feature_names=X_disp.columns,
    )

    fig_w, ax_w = plt.subplots(figsize=(8, 6))
    shap.plots.waterfall(shap_ex, show=False)
    st.pyplot(fig_w)
    plt.close(fig_w)

    # ============================================
    # Interaction SHAPï¼ˆåˆ†é¡ï¼‰
    # ============================================
    st.header("ğŸ”€ Interaction SHAPï¼ˆClass 0ï¼‰")

    interaction_mean = np.abs(interaction_values).mean(axis=0)
    np.fill_diagonal(interaction_mean, 0)

    interaction_df = pd.DataFrame(
        interaction_mean,
        index=X_num.columns,
        columns=X_num.columns
    )
    st.subheader("ğŸ“ˆ Interaction SHAP è¡Œåˆ—")
    st.dataframe(interaction_df.style.background_gradient(cmap="RdBu_r"))

    fig_hm = px.imshow(
        interaction_df,
        text_auto=".2f",
        color_continuous_scale="RdBu_r",
        title="SHAP Interaction Heatmapï¼ˆClass 0ï¼‰"
    )
    st.plotly_chart(fig_hm, width="stretch")

    st.subheader("ğŸ† ç›¸äº’ä½œç”¨ãƒ©ãƒ³ã‚­ãƒ³ã‚° Top 20")
    pairs = []
    cols = X_num.columns
    for i in range(len(cols)):
        for j in range(i+1, len(cols)):
            pairs.append((cols[i], cols[j], interaction_mean[i, j]))

    top_df = (
        pd.DataFrame(pairs, columns=["Feature A", "Feature B", "Mean|Interaction|"])
        .sort_values("Mean|Interaction|", ascending=False)
        .head(20)
    )
    st.dataframe(top_df)
