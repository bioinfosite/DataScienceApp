import streamlit as st
import pandas as pd
from sklearn.metrics import (
    mean_absolute_error,
    mean_absolute_percentage_error,
    mean_squared_error,
    r2_score,
)


def run():
    st.title("ğŸ“‰ èª¤å·®æŒ‡æ¨™ï¼ˆå›å¸°ï¼‰")

    uploaded = st.file_uploader(
        "å®Ÿç¸¾å€¤ï¼ˆyï¼‰ã¨äºˆæ¸¬å€¤ï¼ˆy_predï¼‰ã‚’å«ã‚€ CSV/Excel ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=["csv", "xlsx"],
        key="metrics_uploader",
    )

    if not uploaded:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
        return

    df = (
        pd.read_csv(uploaded)
        if uploaded.name.endswith(".csv")
        else pd.read_excel(uploaded)
    )

    st.subheader("ğŸ“„ ãƒ‡ãƒ¼ã‚¿Preview")
    st.dataframe(df.head())

    y_col = st.selectbox("å®Ÿç¸¾å€¤ (y)", df.columns)
    y_pred_col = st.selectbox("äºˆæ¸¬å€¤ (y_pred)", df.columns)

    y = df[y_col]
    y_pred = df[y_pred_col]

    # NaNé™¤å¤–å‡¦ç†ï¼ˆä¸¡æ–¹ã®NaNã‚’ã¾ã¨ã‚ã¦é™¤å¤–ï¼‰
    valid_df = pd.DataFrame({"y": y, "y_pred": y_pred}).dropna().reset_index(drop=True)
    if len(valid_df) < len(df):
        st.warning(
            f"y, y_predã«NaNãŒå«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚ {len(valid_df)} ä»¶ã®ã¿è¨ˆç®—ã«ä½¿ç”¨ã—ã¾ã™ã€‚NaNè¡Œã¯é™¤å¤–ã•ã‚Œã¾ã™ã€‚"
        )
    y_valid = valid_df["y"].astype(float)
    y_pred_valid = valid_df["y_pred"].astype(float)
    if y_valid.isna().sum() > 0 or y_pred_valid.isna().sum() > 0:
        st.error("NaNãŒæ®‹ã£ã¦ã„ã¾ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    st.subheader("ğŸ“Š è¨ˆç®—çµæœ")

    mae = mean_absolute_error(y_valid, y_pred_valid)
    mape = mean_absolute_percentage_error(y_valid, y_pred_valid)
    mse = mean_squared_error(y_valid, y_pred_valid)
    rmse = mse**0.5
    r2 = r2_score(y_valid, y_pred_valid)

    # è¿½åŠ æŒ‡æ¨™
    from sklearn.metrics import (
        median_absolute_error,
        explained_variance_score,
        max_error,
    )

    medae = median_absolute_error(y_valid, y_pred_valid)
    explained_var = explained_variance_score(y_valid, y_pred_valid)
    maxerr = max_error(y_valid, y_pred_valid)
    # Adjusted R2ï¼ˆè‡ªç”±åº¦èª¿æ•´æ¸ˆã¿æ±ºå®šä¿‚æ•°ï¼‰
    n = len(y_valid)
    p = 1  # å˜å›å¸°ã®å ´åˆã€‚å¤šå¤‰é‡ã®å ´åˆã¯ç‰¹å¾´é‡æ•°ã«å¤‰æ›´
    adj_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1) if n > p + 1 else None

    # ãƒ”ã‚¢ã‚½ãƒ³ãƒ»ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢ä¿‚æ•°
    pearson_corr = y_valid.corr(y_pred_valid, method="pearson")
    spearman_corr = y_valid.corr(y_pred_valid, method="spearman")

    # SMAPEï¼ˆå¯¾ç§°å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®ï¼‰
    smape = (
        100 * (abs(y_valid - y_pred_valid) / ((abs(y_valid) + abs(y_pred_valid)) / 2))
    ).mean()

    # RMSLEï¼ˆäºŒä¹—å¹³å‡å¹³æ–¹å¯¾æ•°èª¤å·®ï¼‰
    import numpy as np

    rmsle = np.sqrt(mean_squared_error(np.log1p(y_valid), np.log1p(y_pred_valid)))

    # æŒ‡æ¨™ã‚’è¾æ›¸ã§ã¾ã¨ã‚ã‚‹
    metrics_dict = {
        "MAE (å¹³å‡çµ¶å¯¾èª¤å·®)": mae,
        "MAPE (å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®)": mape,
        "SMAPE (å¯¾ç§°å¹³å‡çµ¶å¯¾ãƒ‘ãƒ¼ã‚»ãƒ³ãƒˆèª¤å·®)": smape,
        "MSE (å¹³å‡äºŒä¹—èª¤å·®)": mse,
        "RMSE (äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®)": rmse,
        "RMSLE (äºŒä¹—å¹³å‡å¹³æ–¹å¯¾æ•°èª¤å·®)": rmsle,
        "R2 (æ±ºå®šä¿‚æ•°)": r2,
        "Adjusted R2 (è‡ªç”±åº¦èª¿æ•´æ¸ˆã¿æ±ºå®šä¿‚æ•°)": adj_r2,
        "Median Absolute Error (ä¸­å¤®å€¤çµ¶å¯¾èª¤å·®)": medae,
        "Explained Variance (èª¬æ˜åˆ†æ•£ã‚¹ã‚³ã‚¢)": explained_var,
        "Max Error (æœ€å¤§çµ¶å¯¾èª¤å·®)": maxerr,
        "Pearson Correlation (ãƒ”ã‚¢ã‚½ãƒ³ç›¸é–¢ä¿‚æ•°)": pearson_corr,
        "Spearman Correlation (ã‚¹ãƒ”ã‚¢ãƒãƒ³ç›¸é–¢ä¿‚æ•°)": spearman_corr,
    }

    # è¡¨å½¢å¼ã§è¡¨ç¤º
    metrics_df = pd.DataFrame(list(metrics_dict.items()), columns=["æŒ‡æ¨™", "å€¤"])
    st.subheader("ğŸ“Š æŒ‡æ¨™ä¸€è¦§")
    st.dataframe(metrics_df, width="stretch")

    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
    csv_data = metrics_df.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="æŒ‡æ¨™ä¸€è¦§ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=csv_data,
        file_name="metrics_result.csv",
        mime="text/csv",
    )
